# 提供商管理与切换

<cite>
**本文档引用的文件**
- [provision.py](file://open_notebook/ai/provision.py)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py)
- [key_provider.py](file://open_notebook/ai/key_provider.py)
- [provider_config.py](file://open_notebook/domain/provider_config.py)
- [models.py](file://open_notebook/ai/models.py)
- [credentials.py](file://api/routers/credentials.py)
- [models.py](file://api/routers/models.py)
- [ai-providers.md](file://docs/5-CONFIGURATION/ai-providers.md)
- [index.md](file://docs/4-AI-PROVIDERS/index.md)
- [token_utils.py](file://open_notebook/utils/token_utils.py)
</cite>

## 更新摘要
**所做更改**
- 更新提供商优先级策略：DeepSeek在OPC场景中优先级最高，体现成本效益和中英双语支持
- 新增模型偏好配置：针对DeepSeek、通义千问、月之暗面、智谱AI的特定模型偏好列表
- 新增提供商显示名称国际化支持：中英文双语显示名称
- 扩展环境变量自动初始化功能：支持更多中国AI提供商的一键配置

## 目录
1. [简介](#简介)
2. [项目结构](#项目结构)
3. [核心组件](#核心组件)
4. [架构总览](#架构总览)
5. [详细组件分析](#详细组件分析)
6. [中国AI提供商管理](#中国ai提供商管理)
7. [提供商优先级与选择策略](#提供商优先级与选择策略)
8. [依赖关系分析](#依赖关系分析)
9. [性能考虑](#性能考虑)
10. [故障排除指南](#故障排除指南)
11. [结论](#结论)
12. [附录](#附录)

## 简介
本文件面向需要在多个AI提供商之间进行灵活切换与管理的用户与开发者，系统性阐述Open Notebook中的提供商管理体系：包括模型发现机制、连接测试流程、健康检查方法、提供商优先级与自动分配策略、负载均衡与故障转移思路、多提供商并行使用配置、性能监控与成本分析建议，以及动态提供商切换与A/B测试的实现方案。文档以代码为依据，辅以可视化图示，帮助读者快速理解并正确配置与使用。

**更新** 本版本重点更新了提供商优先级策略，将DeepSeek置于OPC场景的首位，体现了对国产AI服务的优先支持和成本效益考量。同时新增了模型偏好配置和提供商显示名称国际化支持，进一步完善了中国AI提供商的管理体验。

## 项目结构
围绕"提供商管理与切换"的核心代码主要分布在以下模块：
- AI层：模型发现、连接测试、密钥提供、模型管理
- 领域层：提供者配置（支持多凭证）
- API层：HTTP路由与前端交互接口
- 文档层：配置与选型指南

```mermaid
graph TB
subgraph "AI层"
A1["provision.py<br/>模型选择与实例化"]
A2["model_discovery.py<br/>模型发现与同步<br/>支持中国AI提供商"]
A3["connection_tester.py<br/>连接测试与单模型测试"]
A4["key_provider.py<br/>数据库→环境变量密钥注入<br/>支持自动初始化"]
A5["models.py<br/>模型与默认模型管理"]
end
subgraph "领域层"
D1["provider_config.py<br/>ProviderConfig/ProviderCredential"]
end
subgraph "API层"
P1["credentials.py<br/>凭据CRUD/测试/发现/注册"]
P2["models.py<br/>模型查询/同步/自动分配/可用性"]
end
subgraph "文档层"
U1["ai-providers.md<br/>配置指南<br/>支持中国AI提供商"]
U2["index.md<br/>提供商对比与选型"]
end
A1 --> A5
A2 --> P2
A3 --> P1
A4 --> A5
A5 --> P2
D1 --> P1
D1 --> P2
P1 --> P2
U1 --> P1
U2 --> P2
```

**图表来源**
- [provision.py](file://open_notebook/ai/provision.py#L9-L61)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L608-L725)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L170-L300)
- [key_provider.py](file://open_notebook/ai/key_provider.py#L236-L298)
- [models.py](file://open_notebook/ai/models.py#L97-L267)
- [provider_config.py](file://open_notebook/domain/provider_config.py#L175-L445)
- [credentials.py](file://api/routers/credentials.py#L94-L387)
- [models.py](file://api/routers/models.py#L165-L771)
- [ai-providers.md](file://docs/5-CONFIGURATION/ai-providers.md#L1-L468)
- [index.md](file://docs/4-AI-PROVIDERS/index.md#L1-L200)

## 核心组件
- 模型发现与同步：按提供商自动拉取可用模型清单，并可批量注册到数据库，支持并发同步所有提供商，现已扩展支持DeepSeek、通义千问、月之暗面、智谱AI等中国AI提供商。
- 连接测试：针对提供商API密钥有效性进行最小调用验证；支持特定模型端到端测试。
- 密钥提供：从数据库Credential记录中读取并注入环境变量，支持复杂提供商（Azure/Vertex/OpenAI-Compatible）的多字段配置，新增环境变量自动初始化功能。
- 模型管理：根据内容长度、显式指定或默认类型选择合适的模型实例；支持大上下文模型自动切换。
- 多凭证配置：每个提供商可维护多个凭证，支持默认凭证与按需切换。
- 自动分配与优先级：基于重构后的提供商优先级与模型偏好，自动为默认槽位分配可用模型。

**更新** 新增的中国AI提供商支持包括DeepSeek（深度求索）、通义千问（Qwen）、月之暗面（Moonshot）、智谱AI（Zhipu），这些提供商均支持中英文显示名称和默认基础URL配置。提供商优先级策略已调整，DeepSeek在OPC场景中优先级最高。

**章节来源**
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L608-L725)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L170-L300)
- [key_provider.py](file://open_notebook/ai/key_provider.py#L236-L298)
- [provision.py](file://open_notebook/ai/provision.py#L9-L61)
- [provider_config.py](file://open_notebook/domain/provider_config.py#L175-L445)
- [models.py](file://api/routers/models.py#L678-L771)

## 架构总览
下图展示了从HTTP请求到AI模型实例化的完整链路，包括密钥注入、模型选择与测试等关键环节。

```mermaid
sequenceDiagram
participant FE as "前端"
participant API as "API路由"
participant KP as "密钥提供(key_provider)"
participant MM as "模型管理(ModelManager)"
participant MF as "esperanto工厂(AIFactory)"
participant PT as "连接测试(connection_tester)"
FE->>API : "POST /models/{id}/test"
API->>MM : "获取模型对象"
MM->>KP : "按模型关联或默认凭证注入环境变量"
KP-->>MM : "环境变量已设置"
MM->>MF : "创建期望的模型实例"
MF-->>MM : "返回模型实例"
API->>PT : "对具体模型执行端到端测试"
PT-->>API : "返回测试结果"
API-->>FE : "返回测试结果"
```

**图表来源**
- [models.py](file://api/routers/models.py#L266-L287)
- [models.py](file://open_notebook/ai/models.py#L101-L176)
- [key_provider.py](file://open_notebook/ai/key_provider.py#L236-L298)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L367-L439)

## 详细组件分析

### 模型发现与同步
- 发现机制：按提供商映射调用对应发现函数，自动分类模型类型（语言/嵌入/TTS/STT），并支持静态列表（如Anthropic、DeepSeek、通义千问、月之暗面、智谱AI）与API枚举（如OpenAI/Gemini/Ollama等）。
- 同步策略：并发调用所有提供商的发现函数，批量去重注册，避免重复写入；支持仅发现不入库的场景。
- 计数查询：按提供商分组统计各类型模型数量，便于UI展示与健康检查。

```mermaid
flowchart TD
Start(["开始"]) --> Prov["选择提供商"]
Prov --> CheckFunc{"是否存在发现函数?"}
CheckFunc --> |否| Warn["记录警告/跳过"]
CheckFunc --> |是| Call["调用发现函数"]
Call --> Parse["解析模型列表并分类"]
Parse --> Register{"是否自动注册?"}
Register --> |否| Return["返回发现结果"]
Register --> |是| Batch["批量去重并注册"]
Batch --> Done(["完成"])
Warn --> Done
Return --> Done
```

**图表来源**
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L608-L725)

**章节来源**
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L173-L204)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L269-L299)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L589-L605)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L632-L697)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L699-L725)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L727-L757)

### 连接测试与健康检查
- 提供商连接测试：对简单提供商使用最小API调用验证；对URL类（Ollama/OpenAI-Compatible）与复杂提供商（Azure/Vertex）采用专用检测逻辑。
- 单模型测试：对具体模型执行端到端调用（语言/嵌入/TTS/STT），返回响应摘要或维度信息，便于快速验证。
- 健康检查：通过"可用性"接口汇总各提供商的凭证状态与能力矩阵，结合esperanto可用提供者集合判断支持的模型类型。

```mermaid
sequenceDiagram
participant API as "API路由"
participant CT as "连接测试"
participant EP as "esperanto工厂"
participant LC as "LangChain适配"
API->>CT : "test_provider_connection(provider, type, config_id)"
CT->>CT : "根据提供商选择专用检测逻辑"
alt URL类提供商
CT-->>API : "返回连接结果"
else 复杂提供商
CT->>EP : "创建模型实例"
EP-->>CT : "返回模型"
CT->>LC : "最小调用验证"
LC-->>CT : "返回结果"
CT-->>API : "返回连接结果"
end
```

**图表来源**
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L170-L300)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L367-L439)

**章节来源**
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L170-L300)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L367-L439)
- [models.py](file://api/routers/models.py#L361-L474)

### 密钥提供与凭证管理
- 数据库优先：优先从Credential记录读取API密钥与基础URL等配置，注入到对应环境变量，确保esperanto工厂能正确初始化。
- 复杂提供商：对Azure/Vertex/OpenAI-Compatible分别处理多字段配置，避免单一环境变量带来的歧义。
- 凭证模型：ProviderConfig支持同一提供商的多个凭证，可设置默认凭证；ProviderCredential包含名称、提供商、密钥、基础URL、端点、模型等字段。
- **新增** 环境变量自动初始化：支持从环境变量一键初始化中国AI提供商配置，包括DeepSeek、通义千问、月之暗面、智谱AI等。

```mermaid
classDiagram
class ProviderConfig {
+credentials : Dict[str, List[ProviderCredential]]
+get_instance()
+get_default_config(provider)
+get_config(provider, config_id)
+add_config(provider, credential)
+delete_config(provider, config_id)
+set_default_config(provider, config_id)
+save()
}
class ProviderCredential {
+id : str
+name : str
+provider : str
+is_default : bool
+api_key : SecretStr
+base_url : str
+model : str
+api_version : str
+endpoint : str
+endpoint_llm : str
+endpoint_embedding : str
+endpoint_stt : str
+endpoint_tts : str
+project : str
+location : str
+credentials_path : str
+to_dict(encrypted)
+from_dict(data, decrypted)
}
ProviderConfig --> ProviderCredential : "包含多个"
```

**图表来源**
- [provider_config.py](file://open_notebook/domain/provider_config.py#L175-L445)

**章节来源**
- [key_provider.py](file://open_notebook/ai/key_provider.py#L236-L298)
- [key_provider.py](file://open_notebook/ai/key_provider.py#L68-L103)
- [provider_config.py](file://open_notebook/domain/provider_config.py#L175-L445)

### 模型选择与默认模型管理
- 内容驱动选择：根据输入内容的token数阈值（例如超过105,000）自动切换到"大上下文模型"，否则按显式model_id或默认类型选择。
- 类型校验：确保返回的模型实例符合期望类型（语言/嵌入/TTS/STT），否则抛出错误提示。
- 默认模型：通过DefaultModels记录管理各类默认槽位（聊天、转换、工具、嵌入、语音等），ModelManager负责按类型获取默认模型。

```mermaid
flowchart TD
S(["开始"]) --> Cnt["计算输入token数"]
Cnt --> GT{"是否超过阈值?"}
GT --> |是| Large["选择大上下文模型"]
GT --> |否| Mid["检查显式model_id"]
Mid --> HasId{"是否有显式ID?"}
HasId --> |是| Explicit["按ID获取模型"]
HasId --> |否| Default["按类型获取默认模型"]
Large --> TypeChk{"类型是否匹配?"}
Explicit --> TypeChk
Default --> TypeChk
TypeChk --> |否| Err["抛出类型不匹配错误"]
TypeChk --> |是| Ret["返回模型实例"]
```

**图表来源**
- [provision.py](file://open_notebook/ai/provision.py#L18-L60)
- [models.py](file://open_notebook/ai/models.py#L220-L264)

**章节来源**
- [provision.py](file://open_notebook/ai/provision.py#L9-L61)
- [models.py](file://open_notebook/ai/models.py#L97-L267)

### 自动分配与提供商优先级
- 优先级策略：定义重构后的提供商优先级列表（如DeepSeek、通义千问、智谱AI、月之暗面、OpenAI、Anthropic、Google、Mistral、Groq、xAI、OpenRouter、Ollama、Azure、OpenAI-Compatible），优先选择高优先级提供商的可用模型。
- 模型偏好：在同提供商内按偏好列表（如OpenAI的gpt-4o/gpt-4/gpt-3.5-turbo）进一步筛选。
- 自动分配：扫描数据库中所有模型，按类型分组，依次为每个默认槽位分配最佳可用模型，返回已分配、跳过与缺失列表。

```mermaid
flowchart TD
A(["开始"]) --> Scan["扫描数据库模型"]
Scan --> Group["按类型分组"]
Group --> Loop{"遍历槽位配置"}
Loop --> Check{"当前槽位已有值?"}
Check --> |是| Skip["跳过该槽位"] --> Next["下一个槽位"]
Check --> |否| Avail{"是否有可用模型?"}
Avail --> |否| Miss["记录缺失"] --> Next
Avail --> |是| Pick["按优先级与偏好选择最佳模型"]
Pick --> Assign["分配到槽位并更新默认记录"]
Assign --> Next
Next --> |循环结束| Save["保存默认记录"] --> End(["结束"])
```

**图表来源**
- [models.py](file://api/routers/models.py#L678-L771)

**章节来源**
- [models.py](file://api/routers/models.py#L86-L109)
- [models.py](file://api/routers/models.py#L678-L771)

### 多提供商并行使用与最佳实践
- 并行发现与同步：API层提供"同步所有提供商"的端点，内部并发调用各提供商发现函数，提升初始建模效率。
- 多凭证并存：同一提供商可配置多个凭证，用于区分环境（开发/生产）、团队成员或不同用途；通过默认凭证与按需切换实现灵活管理。
- 最佳实践：
  - 使用"自动分配默认模型"功能，结合重构后的提供商优先级与模型偏好，减少手动配置。
  - 定期执行"同步所有提供商"，保持模型清单最新。
  - 对于本地/私有部署（Ollama/LM Studio），通过OpenAI-Compatible模式统一接入。

**章节来源**
- [models.py](file://api/routers/models.py#L539-L575)
- [provider_config.py](file://open_notebook/domain/provider_config.py#L326-L410)
- [ai-providers.md](file://docs/5-CONFIGURATION/ai-providers.md#L356-L370)

### 动态提供商切换与A/B测试
- 切换方式：
  - 通过前端或API修改默认模型槽位，实现"动态切换"到另一个提供商的模型。
  - 在同一请求中传入显式model_id，绕过默认模型选择，实现临时切换。
- A/B测试思路：
  - 将同一任务拆分为两个分支，分别使用不同提供商的默认模型或显式模型ID。
  - 收集响应质量、延迟、成本等指标，评估提供商差异。
  - 可结合"单模型测试"接口验证不同模型的端到端可用性。

**章节来源**
- [provision.py](file://open_notebook/ai/provision.py#L28-L33)
- [models.py](file://api/routers/models.py#L266-L287)

## 中国AI提供商管理

### 新增中国AI提供商支持
Open Notebook现已全面支持多家中国AI提供商，包括DeepSeek、通义千问、月之暗面、智谱AI等，这些提供商均具备以下特性：

- **DeepSeek（深度求索）**：支持多类型模型发现，包括推理、编码等专业模型
- **通义千问（Qwen）**：提供完整的语言模型和嵌入模型支持
- **月之暗面（Moonshot）**：专注于长文本处理的Kimi系列模型
- **智谱AI（Zhipu）**：GLM系列大模型的完整支持

### 显示名称国际化支持
所有新增的中国AI提供商均支持中英文显示名称：
- DeepSeek → DeepSeek（英文）
- 通义千问 → Qwen（英文）
- 月之暗面 → Moonshot（英文）
- 智谱AI → Zhipu（英文）

### 默认基础URL配置
每家中国AI提供商都有预设的默认基础URL：
- DeepSeek：https://api.deepseek.com
- 通义千问：https://dashscope.aliyuncs.com/compatible-mode/v1
- 月之暗面：https://api.moonshot.cn/v1
- 智谱AI：https://open.bigmodel.cn/api/paas/v4

### 环境变量自动初始化
系统提供了环境变量自动初始化功能，支持一键配置中国AI提供商：

```mermaid
flowchart TD
Env["检查环境变量"] --> Check{"是否存在API密钥?"}
Check --> |是| Init["自动初始化提供商"]
Check --> |否| Skip["跳过初始化"]
Init --> Create["创建Credential记录"]
Create --> Config["创建ProviderConfig配置"]
Config --> Success["初始化成功"]
Skip --> End["结束"]
Success --> End
```

**图表来源**
- [key_provider.py](file://open_notebook/ai/key_provider.py#L356-L437)

**章节来源**
- [key_provider.py](file://open_notebook/ai/key_provider.py#L316-L358)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L498-L530)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L566-L590)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L593-L610)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L612-L660)

## 提供商优先级与选择策略

### 重构后的优先级顺序
经过重构，提供商优先级已调整为以下顺序：

1. **DeepSeek** - 国产AI的首选提供商（OPC场景优先级最高）
2. **通义千问（Qwen）** - 阿里巴巴旗下的多模态AI
3. **智谱AI（Zhipu）** - 百度旗下的GLM系列大模型
4. **月之暗面（Moonshot）** - 专注长文本处理的Kimi系列
5. **OpenAI** - 国际主流AI服务
6. **Anthropic** - Claude系列AI助手
7. **Google** - Gemini多模态AI
8. **Mistral** - 欧洲开源AI模型
9. **Groq** - 专注于推理速度的AI加速器
10. **xAI** - Elon Musk的Grok模型
11. **OpenRouter** - 模型聚合平台
12. **Ollama** - 本地AI模型运行
13. **Azure** - 微软的企业级AI服务
14. **OpenAI-Compatible** - 兼容OpenAI协议的其他服务

### 选择策略优化
新的优先级策略体现了以下考虑：

- **本土化优先**：DeepSeek、通义千问、智谱AI、月之暗面等中国AI提供商优先，体现对国产AI服务的支持
- **成本效益**：在OPC场景中，DeepSeek优先级最高，体现成本效益和性能平衡
- **功能互补**：不同提供商在不同领域各有优势，通过优先级排序实现最佳组合

### 模型偏好配置
针对中国AI提供商，系统还配置了相应的模型偏好：

- **DeepSeek**：优先选择deepseek-chat、deepseek-reasoner、deepseek-coder等最新模型
- **通义千问**：优先选择qwen-max、qwen-plus等高性能模型
- **智谱AI**：优先选择glm-5、glm-4-plus等旗舰模型
- **月之暗面**：优先选择kimi-k2-5、moonshot-v1-128k等长文本模型

**章节来源**
- [models.py](file://api/routers/models.py#L86-L102)
- [models.py](file://api/routers/models.py#L105-L114)

## 依赖关系分析
- 模块耦合：
  - ModelManager依赖Credential与KeyProvider，确保模型创建前密钥注入完成。
  - API路由依赖ModelManager与Discovery/Tester模块，提供对外服务。
  - ProviderConfig作为领域模型，被API路由与前端交互使用。
- 外部依赖：
  - esperanto工厂：统一创建各类型模型实例。
  - httpx：用于提供商API调用与发现。
  - loguru：统一日志输出。

```mermaid
graph LR
KP["key_provider.py<br/>支持中国AI提供商"] --> MM["models.py(ModelManager)"]
MM --> MF["esperanto(AIFactory)"]
MD["model_discovery.py<br/>扩展中国AI支持"] --> API2["api/routers/models.py"]
CT["connection_tester.py"] --> API1["api/routers/credentials.py"]
PC["provider_config.py"] --> API1
PC --> API2
API1 --> FE["前端"]
API2 --> FE
```

**图表来源**
- [models.py](file://open_notebook/ai/models.py#L101-L176)
- [key_provider.py](file://open_notebook/ai/key_provider.py#L236-L298)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L608-L725)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L170-L300)
- [provider_config.py](file://open_notebook/domain/provider_config.py#L175-L445)
- [credentials.py](file://api/routers/credentials.py#L94-L387)
- [models.py](file://api/routers/models.py#L165-L771)

**章节来源**
- [models.py](file://open_notebook/ai/models.py#L1-L267)
- [key_provider.py](file://open_notebook/ai/key_provider.py#L1-L298)
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L1-L757)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L1-L439)
- [provider_config.py](file://open_notebook/domain/provider_config.py#L1-L445)
- [credentials.py](file://api/routers/credentials.py#L1-L387)
- [models.py](file://api/routers/models.py#L1-L771)

## 性能考虑
- 并发优化：模型发现与同步采用异步并发，显著缩短初始建模时间。
- 缓存与去重：ModelManager通过esperanto工厂缓存模型实例；同步时批量查询现有模型，避免N+1查询。
- 资源控制：连接测试使用最小调用，避免昂贵的全量推理；对TTS/STT提供键格式验证，减少无效调用。
- 成本估算：内置token计数与成本计算工具，便于粗略估算使用成本。
- **新增** 中国AI提供商优化：针对DeepSeek、通义千问等中国AI提供商的网络特点进行了专门优化，提高连接稳定性和响应速度。

**章节来源**
- [model_discovery.py](file://open_notebook/ai/model_discovery.py#L708-L725)
- [models.py](file://open_notebook/ai/models.py#L97-L100)
- [token_utils.py](file://open_notebook/utils/token_utils.py#L15-L47)

## 故障排除指南
- "无可用模型"：检查是否已完成"发现并注册模型"，确认提供商API密钥有效且网络可达。
- "模型类型不匹配"：确认默认模型或显式模型ID对应的类型与调用场景一致。
- "连接失败/超时"：检查提供商端点、API密钥、网络连通性；对Azure/Vertex/OpenAI-Compatible检查多字段配置。
- "速率限制/配额不足"：适当降低并发或等待配额恢复；必要时升级账户或更换提供商。
- "Ollama未运行/模型不存在"：确认Ollama服务状态与模型下载情况。
- **新增** "中国AI提供商连接问题"：检查网络是否能访问对应的中国AI服务端点，确认API密钥正确配置。

**章节来源**
- [provision.py](file://open_notebook/ai/provision.py#L37-L59)
- [connection_tester.py](file://open_notebook/ai/connection_tester.py#L275-L300)
- [ai-providers.md](file://docs/5-CONFIGURATION/ai-providers.md#L450-L468)

## 结论
Open Notebook通过"凭证驱动+模型发现+连接测试+默认模型管理"的体系，实现了对多提供商的灵活管理与切换。借助并发发现、自动分配与类型校验，系统在保证稳定性的同时提升了易用性。配合文档提供的配置与选型指南，用户可以快速完成提供商迁移、并行使用与A/B测试，最终达成性能、成本与隐私的平衡。

**更新** 本次更新重点优化了提供商优先级策略，将DeepSeek置于OPC场景的首位，体现了对国产AI服务的优先支持和成本效益考量。通过环境变量自动初始化、中英文显示名称支持、模型偏好配置等功能，进一步简化了中国AI提供商的配置和使用流程，提升了整体用户体验。

## 附录
- 快速上手步骤（参考文档）：
  - 设置加密密钥后，在"设置→API密钥"中添加凭证并测试连接。
  - 发现并注册模型，然后在"设置→模型"中查看与自动分配默认模型。
  - 使用"单模型测试"验证端到端可用性。
  - **新增** 对于中国AI提供商，可通过环境变量一键初始化配置。
- 相关文档：
  - [AI提供商配置指南](file://docs/5-CONFIGURATION/ai-providers.md#L1-L468)
  - [提供商对比与选型](file://docs/4-AI-PROVIDERS/index.md#L1-L200)